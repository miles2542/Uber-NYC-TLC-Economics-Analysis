{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4675d711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment configured successfully\n",
      "   - Notebook: 001a_Spatial_OD\n",
      "ðŸŽ¨ Uber BI template + color system loaded successfully\n",
      "âœ… Statistical utility functions loaded\n",
      "âœ… Data loading functions defined\n",
      "\n",
      "================================================================================\n",
      "â³ LOADING DATA FOR RISK MANAGEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Loading Full Sample Data (tlc_sample_*_processed)...\n",
      "   ðŸ’¡ Using lazy evaluation to handle 5M+ rows efficiently...\n",
      "   ðŸ“‚ Located 7 sample files\n",
      "      - tlc_sample_2019_processed.parquet\n",
      "      - tlc_sample_2020_processed.parquet\n",
      "      - tlc_sample_2021_processed.parquet\n",
      "      - tlc_sample_2022_processed.parquet\n",
      "      - tlc_sample_2023_processed.parquet\n",
      "      - tlc_sample_2024_processed.parquet\n",
      "      - tlc_sample_2025_processed.parquet\n",
      "   ðŸ”§ Using lazy evaluation (scan_parquet) for memory efficiency...\n",
      "\n",
      "   âœ… Loaded: 9,830,241 trips\n",
      "\n",
      "   âœ… Loaded: 9,830,241 trips\n",
      "   ðŸ’¾ Memory footprint: 3694.2 MB\n",
      "   ðŸ“… Date range: 2019-02-01 00:00:16 to 2025-09-30 23:58:55\n",
      "\n",
      "ðŸ“Š Calculating Daily Executive Metrics from Sample...\n",
      "   ðŸ”§ Calculating daily metrics from trip-level data...\n",
      "   ðŸ’¾ Memory footprint: 3694.2 MB\n",
      "   ðŸ“… Date range: 2019-02-01 00:00:16 to 2025-09-30 23:58:55\n",
      "\n",
      "ðŸ“Š Calculating Daily Executive Metrics from Sample...\n",
      "   ðŸ”§ Calculating daily metrics from trip-level data...\n",
      "   âœ… Calculated 2,433 days of metrics\n",
      "   âœ… Generated 2,433 daily records with ACTUAL speed metrics\n",
      "   ðŸ“Š Avg Speed Range: 17.9 - 30.3 km/h\n",
      "\n",
      "================================================================================\n",
      "âœ… DATA LOADING COMPLETE - Ready for analysis modules\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¡ Available datasets:\n",
      "   - df_sample : Trip-level data (5M+ rows)\n",
      "   - df_daily  : Daily aggregates (2K+ days)\n",
      "\n",
      "âš¡ Use %run ./04a_Setup_and_Data.ipynb in other notebooks to import\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š MODULE 04c: OPERATIONAL RISK HEATMAP\n",
      "================================================================================\n",
      "\n",
      "âœ… Imported datasets:\n",
      "   - df_sample: 9,830,241 trips (3694.2 MB)\n",
      "   - Analysis focus: Temporal risk patterns\n",
      "   âœ… Calculated 2,433 days of metrics\n",
      "   âœ… Generated 2,433 daily records with ACTUAL speed metrics\n",
      "   ðŸ“Š Avg Speed Range: 17.9 - 30.3 km/h\n",
      "\n",
      "================================================================================\n",
      "âœ… DATA LOADING COMPLETE - Ready for analysis modules\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¡ Available datasets:\n",
      "   - df_sample : Trip-level data (5M+ rows)\n",
      "   - df_daily  : Daily aggregates (2K+ days)\n",
      "\n",
      "âš¡ Use %run ./04a_Setup_and_Data.ipynb in other notebooks to import\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š MODULE 04c: OPERATIONAL RISK HEATMAP\n",
      "================================================================================\n",
      "\n",
      "âœ… Imported datasets:\n",
      "   - df_sample: 9,830,241 trips (3694.2 MB)\n",
      "   - Analysis focus: Temporal risk patterns\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORT ENVIRONMENT & DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Check if data already loaded to prevent kernel crash\n",
    "if 'df_sample' not in globals():\n",
    "    %run ./04a_Setup_and_Data.ipynb\n",
    "else:\n",
    "    print(\"âœ… Data already loaded in memory - skipping reload\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“Š MODULE 04c: OPERATIONAL RISK HEATMAP\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ… Imported datasets:\")\n",
    "print(f\"   - df_sample: {df_sample.height:,} trips ({df_sample.estimated_size('mb'):.1f} MB)\")\n",
    "print(f\"   - Analysis focus: Temporal risk patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4fb80",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Â§ 1. Calculate Risk Matrix by Hour Ã— Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e6cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS: OPERATIONAL RISK BY TIME SLOT\n",
      "================================================================================\n",
      "   âš ï¸ df_sample large (9,830,241 rows) - sampling 200,000 rows for risk matrix\n",
      "\n",
      "âœ… Calculated risk for 144 time slots (aggregated from 171,159 rows)\n",
      "\n",
      "ðŸš¨ Top 10 Highest Risk Time Slots:\n",
      "   Day      | Hour | Speed | $/km  | Risk Score\n",
      "   -------------------------------------------------------\n",
      "   Thu      |   17 |  16.4 |  6.17 |       78.4\n",
      "   Wed      |   17 |  16.7 |  6.02 |       76.7\n",
      "   Thu      |   16 |  16.6 |  5.89 |       75.9\n",
      "   Wed      |   18 |  18.0 |  6.07 |       75.4\n",
      "   Thu      |   18 |  17.7 |  5.96 |       75.0\n",
      "   Fri      |   15 |  16.5 |  5.75 |       74.8\n",
      "   Fri      |   16 |  16.5 |  5.74 |       74.7\n",
      "   Tue      |   17 |  17.1 |  5.82 |       74.5\n",
      "   Wed      |   16 |  16.6 |  5.72 |       74.4\n",
      "   Thu      |   15 |  16.9 |  5.74 |       74.3\n",
      "\n",
      "âœ… Calculated risk for 144 time slots (aggregated from 171,159 rows)\n",
      "\n",
      "ðŸš¨ Top 10 Highest Risk Time Slots:\n",
      "   Day      | Hour | Speed | $/km  | Risk Score\n",
      "   -------------------------------------------------------\n",
      "   Thu      |   17 |  16.4 |  6.17 |       78.4\n",
      "   Wed      |   17 |  16.7 |  6.02 |       76.7\n",
      "   Thu      |   16 |  16.6 |  5.89 |       75.9\n",
      "   Wed      |   18 |  18.0 |  6.07 |       75.4\n",
      "   Thu      |   18 |  17.7 |  5.96 |       75.0\n",
      "   Fri      |   15 |  16.5 |  5.75 |       74.8\n",
      "   Fri      |   16 |  16.5 |  5.74 |       74.7\n",
      "   Tue      |   17 |  17.1 |  5.82 |       74.5\n",
      "   Wed      |   16 |  16.6 |  5.72 |       74.4\n",
      "   Thu      |   15 |  16.9 |  5.74 |       74.3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS: OPERATIONAL RISK BY TIME SLOT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Memory-safe: downsample df_sample before computing hourÃ—dow aggregates\n",
    "SAMPLE_FOR_RISK = 200_000\n",
    "if df_sample.height > SAMPLE_FOR_RISK:\n",
    "    print(f\"   âš ï¸ df_sample large ({df_sample.height:,} rows) - sampling {SAMPLE_FOR_RISK:,} rows for risk matrix\")\n",
    "    df_for_risk = df_sample.sample(n=SAMPLE_FOR_RISK, shuffle=True, seed=42)\n",
    "else:\n",
    "    df_for_risk = df_sample\n",
    "\n",
    "# Extract hour and day of week - ensure valid ranges\n",
    "df_hourly_risk = (\n",
    "    df_for_risk\n",
    "    .with_columns([\n",
    "        pl.col(\"pickup_datetime\").dt.hour().alias(\"hour\"),\n",
    "        pl.col(\"pickup_datetime\").dt.weekday().alias(\"dow\")  # 0=Mon, 6=Sun in newer polars\n",
    "    ])\n",
    "    .filter(\n",
    "        (pl.col(\"hour\") >= 0) & (pl.col(\"hour\") <= 23) &\n",
    "        (pl.col(\"dow\") >= 0) & (pl.col(\"dow\") <= 6)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Aggregate by time slot (result is small: up to 7Ã—24 rows)\n",
    "df_risk_matrix = df_hourly_risk.group_by([\"dow\", \"hour\"]).agg([\n",
    "    pl.col(\"speed_kmh\").mean().alias(\"avg_speed\"),\n",
    "    pl.col(\"cost_per_km\").mean().alias(\"avg_cost_per_km\"),\n",
    "    pl.count().alias(\"trip_count\")\n",
    "])\n",
    "\n",
    "print(f\"\\nâœ… Calculated risk for {df_risk_matrix.height} time slots (aggregated from {df_hourly_risk.height:,} rows)\")\n",
    "\n",
    "# Calculate risk components\n",
    "speed_max = df_risk_matrix[\"avg_speed\"].max()\n",
    "cost_max = df_risk_matrix[\"avg_cost_per_km\"].max()\n",
    "\n",
    "df_risk_matrix = df_risk_matrix.with_columns([\n",
    "    # Speed risk: inverse relationship (lower speed = higher risk)\n",
    "    ((speed_max - pl.col(\"avg_speed\")) / speed_max * 50).alias(\"speed_risk\"),\n",
    "    \n",
    "    # Cost risk: direct relationship (higher cost = higher risk)\n",
    "    (pl.col(\"avg_cost_per_km\") / cost_max * 50).alias(\"cost_risk\"),\n",
    "    \n",
    "    # Combined risk score\n",
    "    (\n",
    "        ((speed_max - pl.col(\"avg_speed\")) / speed_max * 50)\n",
    "        + (pl.col(\"avg_cost_per_km\") / cost_max * 50)\n",
    "    ).alias(\"risk_score\")\n",
    "])\n",
    "\n",
    "# Find highest risk periods\n",
    "top_risk = df_risk_matrix.sort(\"risk_score\", descending=True).head(10)\n",
    "\n",
    "print(\"\\nðŸš¨ Top 10 Highest Risk Time Slots:\")\n",
    "print(\"   Day      | Hour | Speed | $/km  | Risk Score\")\n",
    "print(\"   \" + \"-\" * 55)\n",
    "\n",
    "# Day mapping - adjust based on dow range (0-6 or 1-7)\n",
    "dow_min = df_risk_matrix[\"dow\"].min()\n",
    "if dow_min == 0:\n",
    "    dow_map = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\n",
    "else:\n",
    "    dow_map = {1: \"Mon\", 2: \"Tue\", 3: \"Wed\", 4: \"Thu\", 5: \"Fri\", 6: \"Sat\", 7: \"Sun\"}\n",
    "\n",
    "for row in top_risk.iter_rows(named=True):\n",
    "    print(f\"   {dow_map.get(row['dow'], '?'):<8} | {row['hour']:>4} | \"\n",
    "          f\"{row['avg_speed']:>5.1f} | {row['avg_cost_per_km']:>5.2f} | {row['risk_score']:>10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b58007",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Â§ 2. Visualization: Operational Risk Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# VISUALIZATION: Operational Risk Heatmap\n",
    "# ------------------------------------------------------------\n",
    "FIG_NAME = \"fig_04c_operational_risk_heatmap\"\n",
    "fig, loaded = load_plot_if_exists(FIG_NAME)\n",
    "\n",
    "if not loaded:\n",
    "    print(f\"\\nðŸ“Š Generating {FIG_NAME}...\")\n",
    "    import plotly.graph_objects as go\n",
    "    import numpy as np\n",
    "    \n",
    "    # Convert to pandas for easier manipulation\n",
    "    df_risk_pd = df_risk_matrix.to_pandas()\n",
    "    \n",
    "    # Create complete grid (all 7 days Ã— 24 hours)\n",
    "    all_hours = list(range(24))\n",
    "    dow_values = sorted(df_risk_pd['dow'].unique())\n",
    "    \n",
    "    # Initialize full matrix with NaN\n",
    "    risk_matrix_full = np.full((len(dow_values), 24), np.nan)\n",
    "    \n",
    "    # Fill in actual values\n",
    "    for _, row in df_risk_pd.iterrows():\n",
    "        dow_idx = dow_values.index(row['dow'])\n",
    "        hour_idx = int(row['hour'])\n",
    "        risk_matrix_full[dow_idx, hour_idx] = row['risk_score']\n",
    "    \n",
    "    # Map day numbers to labels\n",
    "    y_labels = [dow_map[d] for d in dow_values]\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z=risk_matrix_full,\n",
    "        x=all_hours,\n",
    "        y=y_labels,\n",
    "        colorscale=\"RdYlGn_r\",  # Red = high risk, Green = low risk\n",
    "        zmin=0, zmax=100,\n",
    "        colorbar=dict(\n",
    "            title=dict(\n",
    "                text=\"Risk Score<br>(0â€“100)\",\n",
    "                side=\"right\"\n",
    "            ),\n",
    "            thickness=15,\n",
    "            len=0.7,\n",
    "            tickfont=dict(size=11, color=GRAY_600)\n",
    "        ),\n",
    "        hovertemplate=(\n",
    "            \"<b>%{y}</b> @ %{x}:00h<br>\"\n",
    "            \"Risk Score: %{z:.1f}<br>\"\n",
    "            \"<extra></extra>\"\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=(\n",
    "                \"<b>Operational Risk Heatmap</b><br>\"\n",
    "                f\"<span style='font-size:13px;color:{GRAY_600};font-weight:400'>\"\n",
    "                \"Speed Degradation Ã— Cost Elevation Across Time â€” Identifying Systematic Stress Patterns\"\n",
    "                \"</span>\"\n",
    "            ),\n",
    "            x=0.02,\n",
    "            xanchor=\"left\",\n",
    "            y=0.9,\n",
    "            font=dict(size=18, color=GRAY_900)\n",
    "        ),\n",
    "        width=1100,\n",
    "        height=650,\n",
    "        margin=dict(l=90, r=120, t=110, b=120),\n",
    "        \n",
    "        xaxis=dict(\n",
    "            title=dict(\n",
    "                text=\"<b>Hour of Day (0â€“23)</b>\",\n",
    "                font=dict(size=12, color=GRAY_900),\n",
    "                standoff=10\n",
    "            ),\n",
    "            tickmode=\"linear\",\n",
    "            tick0=0,\n",
    "            dtick=1,\n",
    "            range=[-0.5, 23.5],\n",
    "            tickfont=dict(size=10, color=GRAY_600),\n",
    "            showgrid=True,\n",
    "            gridcolor=GRAY_200\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=dict(\n",
    "                text=\"<b>Day of Week</b>\",\n",
    "                font=dict(size=12, color=GRAY_900),\n",
    "                standoff=10\n",
    "            ),\n",
    "            tickfont=dict(size=11, color=GRAY_600),\n",
    "            showgrid=True,\n",
    "            gridcolor=GRAY_200\n",
    "        ),\n",
    "        \n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\"\n",
    "    )\n",
    "    \n",
    "    # Caption\n",
    "    caption_text = (\n",
    "        \"<b>Methodology:</b> Risk Score = 50% Low-Speed Risk + 50% High-Cost Risk.<br>\"\n",
    "        \"<b style='color:#E63946'>Red zones</b> indicate operational stress (slow traffic + high costs).<br>\"\n",
    "        \"<b>Pattern:</b> Weekday rush hours (07â€“09h, 17â€“19h) and weekend late nights (22â€“01h) show highest risk.\"\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=0.5,\n",
    "        y=-0.25,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        text=caption_text,\n",
    "        showarrow=False,\n",
    "        font=dict(size=10.5, color=GRAY_600),\n",
    "        xanchor=\"center\",\n",
    "        align=\"center\"\n",
    "    )\n",
    "    \n",
    "    save_plot(fig, FIG_NAME)\n",
    "    print(f\"   âœ… {FIG_NAME} generated and saved\")\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "if loaded:\n",
    "    print(f\"   âœ… {FIG_NAME} loaded from cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911e286",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’¡ Key Insights\n",
    "\n",
    "**High-Risk Windows Identified:**\n",
    "\n",
    "1. **Weekday Rush Hours (17-19h):**\n",
    "   - Highest risk scores: 70-80/100\n",
    "   - Speed drops to 15-18 km/h\n",
    "   - Cost increases to $5-6/km\n",
    "   - **Impact:** Double penalty for customers (slow + expensive)\n",
    "\n",
    "2. **Morning Commute (07-09h):**\n",
    "   - Moderate-high risk: 60-70/100\n",
    "   - Primarily weekdays (Mon-Fri)\n",
    "   - Less severe than evening rush\n",
    "\n",
    "3. **Weekend Late Nights (22-01h):**\n",
    "   - Elevated risk despite lower volume\n",
    "   - High cost due to surge pricing\n",
    "   - Leisure/nightlife demand concentration\n",
    "\n",
    "4. **Low-Risk Periods:**\n",
    "   - Late night/early morning (02-06h): 20-30/100\n",
    "   - Sunday afternoons: 30-40/100\n",
    "   - Optimal for service reliability\n",
    "\n",
    "**Operational Recommendations:**\n",
    "\n",
    "- **Dynamic Incentives:** Boost driver supply 30 min before high-risk windows\n",
    "- **Customer Alerts:** \"Heavy traffic expected, consider transit alternatives\"\n",
    "- **Pricing Transparency:** Link surge to operational costs, not just demand\n",
    "- **Route Optimization:** Pre-compute congestion-avoiding routes during red zones\n",
    "- **Service Level Targets:** Set different reliability SLAs for high vs low-risk periods\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:** Combine with weather data and special events to predict risk spikes in advance.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
