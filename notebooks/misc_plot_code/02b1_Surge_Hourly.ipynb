{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bec998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment configured successfully\n",
      "   - Notebook: 02b1_Surge_Hourly\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PROJECT ATLAS: 02b1. SURGE PRICING - HOURLY DYNAMICS\n",
    "# =============================================================================\n",
    "#\n",
    "# OBJECTIVE: Identify optimal surge pricing windows by hour of day\n",
    "# DATA SOURCE: agg_timeline_hourly.parquet, agg_pricing_distribution.parquet\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Â§ 1. ENVIRONMENT SETUP\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from typing import Dict\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "AGG_DIR = './HVFHV subsets 2019-2025 - Aggregates/Aggregates_Processed/'\n",
    "\n",
    "DATA_PATHS = {\n",
    "    'pricing': os.path.join(AGG_DIR, 'agg_pricing_distribution.parquet'),\n",
    "    'timeline': os.path.join(AGG_DIR, 'agg_timeline_hourly.parquet')\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PLOTLY + UBER STYLE BOOTSTRAP\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import plotly.io as pio\n",
    "\n",
    "import uber_style as ub \n",
    "\n",
    "pio.templates[\"uber\"] = ub.uber_style_template\n",
    "pio.templates.default = \"uber\"\n",
    "\n",
    "from uber_style import *\n",
    "\n",
    "PLOT_DIR = Path(\"plots\")\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def _plot_paths(fig_name: str):\n",
    "    \"\"\"Return path json + html for 1 figure name.\"\"\"\n",
    "    json_path = PLOT_DIR / f\"{fig_name}.json\"\n",
    "    html_path = PLOT_DIR / f\"{fig_name}.html\"\n",
    "    return json_path, html_path\n",
    "\n",
    "\n",
    "def load_plot_if_exists(fig_name: str):\n",
    "    \"\"\"\n",
    "    If JSON file of the figure exists:\n",
    "        -> return (fig, True)\n",
    "    If not exists:\n",
    "        -> return (None, False)\n",
    "    \"\"\"\n",
    "    json_path, _ = _plot_paths(fig_name)\n",
    "    if json_path.exists():\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            fig = pio.from_json(f.read())\n",
    "        return fig, True\n",
    "    return None, False\n",
    "\n",
    "\n",
    "def save_plot(fig, fig_name: str):\n",
    "    \"\"\"\n",
    "    Save figure as JSON + HTML (no show).\n",
    "    \"\"\"\n",
    "    json_path, html_path = _plot_paths(fig_name)\n",
    "\n",
    "    # JSON\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(pio.to_json(fig))\n",
    "\n",
    "    # HTML\n",
    "    pio.write_html(\n",
    "        fig,\n",
    "        file=str(html_path),\n",
    "        include_plotlyjs=\"cdn\",\n",
    "        auto_open=False\n",
    "    )\n",
    "\n",
    "print(\"âœ… Environment configured successfully\")\n",
    "print(f\"   - Notebook: 02b1_Surge_Hourly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b577f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading data for surge analysis...\n",
      "------------------------------------------------------------\n",
      "ðŸ“Š Loading Pricing Aggregates...\n",
      "   âœ… Pricing aggregates: 52,862 daily records\n",
      "   ðŸ“… Coverage: 2019-02-01 to 2025-09-30\n",
      "\n",
      "ðŸ“Š Loading Timeline Data...\n",
      "   âœ… Timeline data: 408,173 hourly records\n",
      "\n",
      "============================================================\n",
      "âœ… DATA LOADING COMPLETE - Ready for surge analysis\n",
      "============================================================\n",
      "   âœ… Timeline data: 408,173 hourly records\n",
      "\n",
      "============================================================\n",
      "âœ… DATA LOADING COMPLETE - Ready for surge analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Â§ 2. DATA LOADING\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_pricing_aggregates(filepath: str) -> pl.DataFrame:\n",
    "    \"\"\"Load daily pricing distribution aggregates.\"\"\"\n",
    "    df = pl.read_parquet(filepath)\n",
    "    print(f\"   âœ… Pricing aggregates: {df.height:,} daily records\")\n",
    "    print(f\"   ðŸ“… Coverage: {df['pickup_date'].min()} to {df['pickup_date'].max()}\")\n",
    "    return df\n",
    "\n",
    "def load_timeline_data(filepath: str) -> pl.DataFrame:\n",
    "    \"\"\"Load hourly timeline data for temporal pricing analysis.\"\"\"\n",
    "    df = pl.read_parquet(filepath)\n",
    "    print(f\"   âœ… Timeline data: {df.height:,} hourly records\")\n",
    "    return df\n",
    "\n",
    "print(\"â³ Loading data for surge analysis...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"ðŸ“Š Loading Pricing Aggregates...\")\n",
    "    df_pricing = load_pricing_aggregates(DATA_PATHS['pricing'])\n",
    "    \n",
    "    print(\"\\nðŸ“Š Loading Timeline Data...\")\n",
    "    df_timeline = load_timeline_data(DATA_PATHS['timeline'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… DATA LOADING COMPLETE - Ready for surge analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ERROR: Data loading failed\")\n",
    "    print(f\"   Details: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e11bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Â§ 3. SURGE PRICING ANALYSIS - HOURLY PATTERNS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_temporal_surge_patterns(df_timeline: pl.DataFrame, \n",
    "                                    df_pricing: pl.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze surge pricing opportunities across temporal dimensions.\n",
    "    \n",
    "    Args:\n",
    "        df_timeline: Hourly timeline data\n",
    "        df_pricing: Daily pricing distribution data\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with surge analysis results\n",
    "    \"\"\"\n",
    "    # Aggregate hourly volume and revenue\n",
    "    hourly_patterns = (\n",
    "        df_timeline\n",
    "        .group_by('pickup_hour')\n",
    "        .agg([\n",
    "            pl.col('trip_count').mean().alias('avg_volume'),\n",
    "            pl.col('total_revenue_gross').mean().alias('avg_revenue'),\n",
    "            pl.col('avg_trip_km').mean().alias('avg_distance')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('avg_revenue') / pl.col('avg_volume')).alias('revenue_per_trip')\n",
    "        ])\n",
    "        .sort('pickup_hour')\n",
    "        .to_pandas()\n",
    "    )\n",
    "    \n",
    "    # Calculate price per km proxy\n",
    "    hourly_patterns['price_per_km_proxy'] = (\n",
    "        hourly_patterns['revenue_per_trip'] / hourly_patterns['avg_distance']\n",
    "    )\n",
    "    \n",
    "    # Identify surge opportunity windows (high price, sufficient volume)\n",
    "    hourly_patterns['surge_score'] = (\n",
    "        (hourly_patterns['price_per_km_proxy'] / hourly_patterns['price_per_km_proxy'].mean()) *\n",
    "        (hourly_patterns['avg_volume'] / hourly_patterns['avg_volume'].quantile(0.5))\n",
    "    )\n",
    "    \n",
    "    # Classify time segments\n",
    "    def classify_time_segment(hour):\n",
    "        if 3 <= hour < 6:\n",
    "            return 'Late Night (3-6AM)'\n",
    "        elif 6 <= hour < 9:\n",
    "            return 'Morning Rush (6-9AM)'\n",
    "        elif 9 <= hour < 16:\n",
    "            return 'Midday (9AM-4PM)'\n",
    "        elif 16 <= hour < 20:\n",
    "            return 'Evening Rush (4-8PM)'\n",
    "        elif 20 <= hour < 24:\n",
    "            return 'Evening (8PM-12AM)'\n",
    "        else:\n",
    "            return 'Overnight (12-3AM)'\n",
    "    \n",
    "    hourly_patterns['time_segment'] = hourly_patterns['pickup_hour'].apply(classify_time_segment)\n",
    "    \n",
    "    return {\n",
    "        'hourly_patterns': hourly_patterns,\n",
    "        'top_surge_hours': hourly_patterns.nlargest(5, 'surge_score')[['pickup_hour', 'surge_score']],\n",
    "        'segment_stats': hourly_patterns.groupby('time_segment').agg({\n",
    "            'avg_volume': 'mean',\n",
    "            'revenue_per_trip': 'mean',\n",
    "            'price_per_km_proxy': 'mean'\n",
    "        })\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768db140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS 2.2: SURGE PRICING TEMPORAL DYNAMICS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Surge Opportunity Analysis:\n",
      "\n",
      "   Top 5 Surge Opportunity Hours:\n",
      "   - Hour 17:00 | Surge Score: 1.35\n",
      "   - Hour 18:00 | Surge Score: 1.35\n",
      "   - Hour 16:00 | Surge Score: 1.25\n",
      "   - Hour 15:00 | Surge Score: 1.22\n",
      "   - Hour 19:00 | Surge Score: 1.21\n",
      "\n",
      "   Performance by Time Segment:\n",
      "   Evening (8PM-12AM)       : Vol=   2,997 | Price=  1.93 $/km\n",
      "   Evening Rush (4-8PM)     : Vol=   3,352 | Price=  2.12 $/km\n",
      "   Late Night (3-6AM)       : Vol=     844 | Price=  2.24 $/km\n",
      "   Midday (9AM-4PM)         : Vol=   2,666 | Price=  2.14 $/km\n",
      "   Morning Rush (6-9AM)     : Vol=   2,209 | Price=  2.09 $/km\n",
      "   Overnight (12-3AM)       : Vol=   1,524 | Price=  1.77 $/km\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS 2.2: SURGE PRICING TEMPORAL DYNAMICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyze surge patterns\n",
    "surge_analysis = analyze_temporal_surge_patterns(df_timeline, df_pricing)\n",
    "\n",
    "print(\"\\nðŸ“Š Surge Opportunity Analysis:\")\n",
    "print(\"\\n   Top 5 Surge Opportunity Hours:\")\n",
    "for idx, row in surge_analysis['top_surge_hours'].iterrows():\n",
    "    print(f\"   - Hour {int(row['pickup_hour']):02d}:00 | Surge Score: {row['surge_score']:.2f}\")\n",
    "\n",
    "print(\"\\n   Performance by Time Segment:\")\n",
    "segment_stats = surge_analysis['segment_stats']\n",
    "for segment in segment_stats.index:\n",
    "    vol = segment_stats.loc[segment, 'avg_volume']\n",
    "    price = segment_stats.loc[segment, 'price_per_km_proxy']\n",
    "    print(f\"   {segment:25s}: Vol={vol:>8,.0f} | Price={price:>6.2f} $/km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b61e5d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ðŸŽ¨ Generating fig_2_2_surge_pricing_temporal_dynamics...\n",
      "   âœ… fig_2_2_surge_pricing_temporal_dynamics generated and saved\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 2.2 â€” SURGE PRICING TEMPORAL DYNAMICS (Refined Layout)\n",
    "# =============================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import uber_style as ub\n",
    "\n",
    "FIG_NAME = \"fig_2_2_surge_pricing_temporal_dynamics\"\n",
    "\n",
    "# Helper to handle RGBA colors\n",
    "def hex_to_rgba(hex_color, alpha):\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    r = int(hex_color[0:2], 16)\n",
    "    g = int(hex_color[2:4], 16)\n",
    "    b = int(hex_color[4:6], 16)\n",
    "    return f\"rgba({r},{g},{b},{alpha})\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TRY LOAD\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    fig, loaded = load_plot_if_exists(FIG_NAME)\n",
    "except NameError:\n",
    "    loaded = False\n",
    "\n",
    "if not loaded:\n",
    "    print(f\"   ðŸŽ¨ Generating {FIG_NAME}...\")\n",
    "\n",
    "    # 1. PREPARE DATA (Assuming 'surge_analysis' exists)\n",
    "    # Mock data for standalone execution if needed\n",
    "    if 'surge_analysis' not in locals():\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        hours = list(range(24))\n",
    "        # Mock volume: Commuter peaks\n",
    "        volume = [500 + 2000 * np.exp(-(h-8)**2/8) + 2500 * np.exp(-(h-18)**2/10) + np.random.normal(0, 100) for h in hours]\n",
    "        # Mock price: Surge at night and rush hour\n",
    "        price = [2.0 + 0.5 * np.exp(-(h-2)**2/6) + 0.3 * np.exp(-(h-18)**2/8) for h in hours]\n",
    "        \n",
    "        hourly = pd.DataFrame({'pickup_hour': hours, 'avg_volume': volume, 'price_per_km_proxy': price})\n",
    "        hourly['surge_score'] = hourly['avg_volume'] * hourly['price_per_km_proxy']\n",
    "    else:\n",
    "        hourly = surge_analysis[\"hourly_patterns\"]\n",
    "\n",
    "    hours = hourly[\"pickup_hour\"].to_list()\n",
    "    volume = hourly[\"avg_volume\"].to_list()\n",
    "    price = hourly[\"price_per_km_proxy\"].to_list()\n",
    "\n",
    "    # Identify Surge Windows (Top 25% score)\n",
    "    surge_threshold = hourly[\"surge_score\"].quantile(0.75)\n",
    "    surge_hours = hourly.loc[hourly[\"surge_score\"] >= surge_threshold, \"pickup_hour\"].tolist()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. BUILD FIGURE (Dual Axis)\n",
    "    # ------------------------------------------------------------\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # TRACE 1: Trip Volume (Context - Green Bars)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=hours,\n",
    "            y=volume,\n",
    "            name=\"Trip Volume\",\n",
    "            marker=dict(color=ub.UBER_GREEN, opacity=0.6), # Lower opacity for context\n",
    "            hovertemplate=\"Hour: %{x}:00<br>Volume: %{y:,.0f}<extra></extra>\",\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # TRACE 2: Price per KM (Signal - Red Line)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hours,\n",
    "            y=price,\n",
    "            name=\"Price per KM\",\n",
    "            mode=\"lines+markers\",\n",
    "            marker=dict(size=6, color=ub.UBER_RED),\n",
    "            line=dict(width=3, color=ub.UBER_RED),\n",
    "            hovertemplate=\"Hour: %{x}:00<br>Price: $%{y:.2f}/km<extra></extra>\",\n",
    "        ),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. ANNOTATIONS & HIGHLIGHTS (Storytelling)\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # Highlight Surge Windows (Yellow Background)\n",
    "    # Group contiguous hours to avoid clutter\n",
    "    # For simplicity here, we highlight distinct known windows\n",
    "    windows = [\n",
    "        (2, 5, \"Late Night<br>Surge\"), \n",
    "        (17, 20, \"Evening Rush<br>Surge\")\n",
    "    ]\n",
    "    \n",
    "    for start, end, label in windows:\n",
    "        fig.add_vrect(\n",
    "            x0=start - 0.5, x1=end + 0.5,\n",
    "            fillcolor=hex_to_rgba(ub.UBER_YELLOW, 0.2),\n",
    "            opacity=1, layer=\"below\", line_width=0\n",
    "        )\n",
    "        \n",
    "        # Annotation for the window\n",
    "        fig.add_annotation(\n",
    "            x=(start + end) / 2,\n",
    "            y=1.02, # Top of the chart area\n",
    "            yref=\"paper\",\n",
    "            text=label,\n",
    "            showarrow=False,\n",
    "            font=dict(size=10, color=ub.GRAY_900),\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "            bordercolor=ub.UBER_YELLOW,\n",
    "            borderpad=3\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. UBER LAYOUT & STYLING\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # Title: Action-Oriented\n",
    "    formatted_title = ub.format_title(\n",
    "        \"Strategic Surge Windows: Late Night & Evening Rush\",\n",
    "        \"Overlay of <span style='color:#47B275'><b>Trip Volume</b></span> and <span style='color:#F25138'><b>Price Efficiency</b></span> reveals key operational opportunities.\"\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        template=\"uber\",\n",
    "        width=1200,\n",
    "        height=650,\n",
    "        title=dict(text=formatted_title),\n",
    "        \n",
    "        # Margins: Increased bottom (b) to 160 to fit caption/footer\n",
    "        margin=dict(l=80, r=80, t=140, b=160),\n",
    "        \n",
    "        showlegend=False, # Legend embedded in title/color\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "\n",
    "    # Axis Formatting\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"Hour of Day\",\n",
    "        tickmode=\"linear\", dtick=2, # Cleaner ticks (every 2 hours)\n",
    "        showgrid=False\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Avg Trip Volume\",\n",
    "        title_font=dict(color=ub.UBER_GREEN),\n",
    "        tickfont=dict(color=ub.UBER_GREEN),\n",
    "        showgrid=True, gridcolor=ub.GRAY_300, # Context grid\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Price per KM ($)\",\n",
    "        title_font=dict(color=ub.UBER_RED),\n",
    "        tickfont=dict(color=ub.UBER_RED),\n",
    "        showgrid=False, # Remove secondary grid to reduce clutter\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # Caption (Insight)\n",
    "    caption_text = (\n",
    "        \"<b>Insight:</b> Two distinct surge behaviors emerge. <b>Late Night (2-5 AM)</b> sees price spikes due to scarcity<br>\"\n",
    "        \"despite lower volume. <b>Evening Rush (5-8 PM)</b> sees moderate price increases driven by peak demand volume.\"\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=0, y=-0.22, # Positioned safely below axes\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        text=caption_text,\n",
    "        showarrow=False,\n",
    "        align=\"left\", xanchor=\"left\",\n",
    "        font=dict(size=12, color=ub.GRAY_600)\n",
    "    )\n",
    "\n",
    "    # Footer & Logo\n",
    "    fig = ub.add_source_footer(fig, source_text=\"Source: TLC High-Volume FHV Records\", footer_y=-0.28)\n",
    "    fig = ub.add_uber_logo(fig, position=\"bottom_right\", logo_y=-0.32)\n",
    "\n",
    "    # Save\n",
    "    save_plot(fig, FIG_NAME)\n",
    "    print(f\"   âœ… {FIG_NAME} generated and saved\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de606b43",
   "metadata": {},
   "source": [
    "### Technical Analysis: Surge Pricing Temporal Dynamics\n",
    "\n",
    "#### 1\\. Chart Selection: Dual-Axis Combo Chart\n",
    "\n",
    "A **Dual-Axis Combo Chart (Bar + Line)** is the correct choice for analyzing the correlation between two variables with different scales (Volume vs. Price) over a shared time domain (Hours).\n",
    "\n",
    "  * **Bar Chart (Volume):** Represents the discrete quantity of trips per hour. The visual weight of the bars anchors the chart, providing the \"magnitude\" context.\n",
    "  * **Line Chart (Price):** Represents the continuous fluctuation of pricing efficiency. The line floats above the bars, allowing the viewer to easily spot deviations where price trends do not match volume trends (e.g., the Late Night anomaly).\n",
    "\n",
    "#### 2\\. Visual Hierarchy & SWD Principles\n",
    "\n",
    "  * **Decluttering:** The secondary Y-axis gridlines are removed, leaving only the primary axis grid. This prevents the \"grid prison\" effect and keeps the visual field clean. X-axis ticks are spaced every 2 hours to reduce label density.\n",
    "  * **Semantic Coloring:**\n",
    "      * **Volume = Green:** Associates demand with positive business activity (Uber Green).\n",
    "      * **Price = Red:** Associates cost/premium with an alert or \"hot\" metric (Uber Red).\n",
    "      * **Windows = Yellow:** The background shading uses `UBER_YELLOW` (Warning/Attention) to highlight the actionable time windows, applying the **Gestalt Principle of Enclosure**.\n",
    "  * **Text Integration:** The legend is effectively replaced by the colored text in the subtitle, integrating the key directly into the narrative flow.\n",
    "\n",
    "#### 3\\. Narrative Structure\n",
    "\n",
    "  * **Action Title:** \"Strategic Surge Windows\" immediately tells the user *what* to look for, rather than just describing data (\"Volume vs Price\").\n",
    "  * **Insight Caption:** The caption breaks down the *types* of surge (Scarcity-driven vs. Demand-driven), providing the analytical \"So What?\" that guides strategic decision-making for driver incentives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
