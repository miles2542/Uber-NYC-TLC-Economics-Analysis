{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1ef58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured successfully\n",
      "   - Notebook: 001a_Spatial_OD\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PROJECT ATLAS: 01a. SPATIAL DISTRIBUTION (OD ANALYSIS)\n",
    "# =============================================================================\n",
    "#\n",
    "# OBJECTIVE: Analyze spatial distribution of origin-destination flows\n",
    "# DATA SOURCE: agg_network_monthly.parquet\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ¬ß 1. ENVIRONMENT SETUP\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from typing import Dict\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "AGG_DIR = './HVFHV subsets 2019-2025 - Aggregates/Aggregates_Processed/'\n",
    "\n",
    "DATA_PATHS = {\n",
    "    'network': os.path.join(AGG_DIR, 'agg_network_monthly.parquet')\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PLOTLY + UBER STYLE BOOTSTRAP\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import plotly.io as pio\n",
    "\n",
    "import uber_style as ub \n",
    "\n",
    "pio.templates[\"uber\"] = ub.uber_style_template\n",
    "pio.templates.default = \"uber\"\n",
    "\n",
    "from uber_style import *\n",
    "\n",
    "PLOT_DIR = Path(\"plots\")\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def _plot_paths(fig_name: str):\n",
    "    \"\"\"Return path json + html for 1 figure name.\"\"\"\n",
    "    json_path = PLOT_DIR / f\"{fig_name}.json\"\n",
    "    html_path = PLOT_DIR / f\"{fig_name}.html\"\n",
    "    return json_path, html_path\n",
    "\n",
    "\n",
    "def load_plot_if_exists(fig_name: str):\n",
    "    \"\"\"\n",
    "    If JSON file of the figure exists:\n",
    "        -> return (fig, True)\n",
    "    If not exists:\n",
    "        -> return (None, False)\n",
    "    \"\"\"\n",
    "    json_path, _ = _plot_paths(fig_name)\n",
    "    if json_path.exists():\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            fig = pio.from_json(f.read())\n",
    "        return fig, True\n",
    "    return None, False\n",
    "\n",
    "\n",
    "def save_plot(fig, fig_name: str):\n",
    "    \"\"\"\n",
    "    Save figure as JSON + HTML (no show).\n",
    "    \"\"\"\n",
    "    json_path, html_path = _plot_paths(fig_name)\n",
    "\n",
    "    # JSON\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(pio.to_json(fig))\n",
    "\n",
    "    # HTML\n",
    "    pio.write_html(\n",
    "        fig,\n",
    "        file=str(html_path),\n",
    "        include_plotlyjs=\"cdn\",\n",
    "        auto_open=False\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Environment configured successfully\")\n",
    "print(f\"   - Notebook: 001a_Spatial_OD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5a3f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading data for spatial analysis...\n",
      "------------------------------------------------------------\n",
      "üìä Loading Network Data (agg_network_monthly)...\n",
      "   ‚úÖ Loaded: 4,567,992 route-month combinations\n",
      "   üìÖ Time range: 2019-2025\n",
      "   ‚úÖ Loaded: 4,567,992 route-month combinations\n",
      "   üìÖ Time range: 2019-2025\n",
      "   üåç Unique routes: 66,241\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA LOADING COMPLETE - Ready for spatial analysis\n",
      "   Note: Only ¬ß3 Spatial OD Analysis in this notebook\n",
      "============================================================\n",
      "   üåç Unique routes: 66,241\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA LOADING COMPLETE - Ready for spatial analysis\n",
      "   Note: Only ¬ß3 Spatial OD Analysis in this notebook\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ¬ß 2. DATA LOADING\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_network_data(filepath: str) -> pl.DataFrame:\n",
    "    \"\"\"Load and validate network (OD) aggregated data.\"\"\"\n",
    "    df = pl.read_parquet(filepath)\n",
    "    \n",
    "    required_cols = ['pickup_borough', 'dropoff_borough', 'trip_count', \n",
    "                     'PULocationID', 'DOLocationID', 'pickup_year', 'pickup_month']\n",
    "    missing = [col for col in required_cols if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "    \n",
    "    assert df.height > 0, \"Network data is empty\"\n",
    "    assert df['trip_count'].min() >= 0, \"Negative trip counts detected\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚è≥ Loading data for spatial analysis...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"üìä Loading Network Data (agg_network_monthly)...\")\n",
    "    df_network = load_network_data(DATA_PATHS['network'])\n",
    "    print(f\"   ‚úÖ Loaded: {df_network.height:,} route-month combinations\")\n",
    "    print(f\"   üìÖ Time range: {df_network['pickup_year'].min()}-{df_network['pickup_year'].max()}\")\n",
    "    print(f\"   üåç Unique routes: {df_network.select([pl.col('PULocationID'), pl.col('DOLocationID')]).n_unique():,}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA LOADING COMPLETE - Ready for spatial analysis\")\n",
    "    print(\"   Note: Only ¬ß3 Spatial OD Analysis in this notebook\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR: Data loading failed\")\n",
    "    print(f\"   Details: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6f0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ¬ß 3. SPATIAL ANALYSIS - OD MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "def create_od_matrix(df_network: pl.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate Origin-Destination matrix aggregated by borough.\"\"\"\n",
    "    od_aggregated = (\n",
    "        df_network\n",
    "        .filter(\n",
    "            pl.col('pickup_borough').is_not_null() & \n",
    "            pl.col('dropoff_borough').is_not_null()\n",
    "        )\n",
    "        .group_by(['pickup_borough', 'dropoff_borough'])\n",
    "        .agg(pl.col('trip_count').sum().alias('total_trips'))\n",
    "        .sort('total_trips', descending=True)\n",
    "    )\n",
    "    \n",
    "    od_matrix = (\n",
    "        od_aggregated\n",
    "        .pivot(on='dropoff_borough', index='pickup_borough', values='total_trips')\n",
    "        .fill_null(0)\n",
    "    )\n",
    "    \n",
    "    od_matrix_pd = od_matrix.to_pandas().set_index('pickup_borough')\n",
    "    \n",
    "    # Sort by volume\n",
    "    row_order = od_matrix_pd.sum(axis=1).sort_values(ascending=False).index\n",
    "    col_order = od_matrix_pd.sum(axis=0).sort_values(ascending=False).index\n",
    "    od_matrix_pd = od_matrix_pd.loc[row_order, col_order]\n",
    "    \n",
    "    return od_matrix_pd\n",
    "\n",
    "def calculate_flow_metrics(df_network: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Calculate internal vs inter-borough flow metrics.\"\"\"\n",
    "    flow_classified = (\n",
    "        df_network\n",
    "        .with_columns([\n",
    "            pl.when(pl.col('pickup_borough') == pl.col('dropoff_borough'))\n",
    "            .then(pl.lit('Internal (Same Borough)'))\n",
    "            .otherwise(pl.lit('Inter-Borough (Cross)'))\n",
    "            .alias('flow_category'),\n",
    "            \n",
    "            (pl.col('pickup_borough') + ' ‚Üí ' + pl.col('dropoff_borough')).alias('route_label')\n",
    "        ])\n",
    "        .group_by(['pickup_borough', 'flow_category'])\n",
    "        .agg([\n",
    "            pl.col('trip_count').sum().alias('total_trips'),\n",
    "            pl.col('avg_duration_min').mean().alias('avg_duration'),\n",
    "            pl.col('avg_cost').mean().alias('avg_cost')\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    return flow_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02417a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS 1.1: ORIGIN-DESTINATION FLOW MATRIX\n",
      "================================================================================\n",
      "\n",
      "üìä OD Matrix Summary Statistics:\n",
      "   Total origin boroughs: 6\n",
      "   Total destination boroughs: 6\n",
      "   Total trips captured: 982,546,658\n",
      "\n",
      "   Top 3 routes by volume:\n",
      "   1. Manhattan ‚Üí Manhattan: 284,455,212 trips\n",
      "   2. Brooklyn ‚Üí Brooklyn: 202,815,320 trips\n",
      "   3. Queens ‚Üí Queens: 134,154,641 trips\n",
      "\n",
      "üìä OD Matrix Summary Statistics:\n",
      "   Total origin boroughs: 6\n",
      "   Total destination boroughs: 6\n",
      "   Total trips captured: 982,546,658\n",
      "\n",
      "   Top 3 routes by volume:\n",
      "   1. Manhattan ‚Üí Manhattan: 284,455,212 trips\n",
      "   2. Brooklyn ‚Üí Brooklyn: 202,815,320 trips\n",
      "   3. Queens ‚Üí Queens: 134,154,641 trips\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS 1.1: ORIGIN-DESTINATION FLOW MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "od_matrix = create_od_matrix(df_network)\n",
    "\n",
    "print(\"\\nüìä OD Matrix Summary Statistics:\")\n",
    "print(f\"   Total origin boroughs: {len(od_matrix.index)}\")\n",
    "print(f\"   Total destination boroughs: {len(od_matrix.columns)}\")\n",
    "print(f\"   Total trips captured: {od_matrix.sum().sum():,.0f}\")\n",
    "print(f\"\\n   Top 3 routes by volume:\")\n",
    "\n",
    "top_routes = od_matrix.stack().sort_values(ascending=False).head(3)\n",
    "for i, (idx, value) in enumerate(top_routes.items(), 1):\n",
    "    origin, dest = idx\n",
    "    print(f\"   {i}. {origin} ‚Üí {dest}: {value:,.0f} trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81536d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 1.1 ‚Äî OD HEATMAP (Refined: Using Uber Style Module)\n",
    "# =============================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uber_style as ub  # Importing the provided style module\n",
    "\n",
    "FIG_NAME = \"fig_1_1_od_heatmap\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. LOAD / SAVE LOGIC\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    fig, loaded = load_plot_if_exists(FIG_NAME)\n",
    "except NameError:\n",
    "    loaded = False\n",
    "\n",
    "if not loaded:\n",
    "    print(f\"   üé® Generating {FIG_NAME}...\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1. PREPARE DATA\n",
    "    # ------------------------------------------------------------\n",
    "    # Mock data generation if 'od_matrix' is missing (for standalone execution)\n",
    "    if 'od_matrix' not in locals():\n",
    "        boroughs = ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island', 'EWR']\n",
    "        # Generate dummy data with Power Law distribution characteristics\n",
    "        data = np.random.lognormal(mean=8, sigma=2, size=(6, 6))\n",
    "        od_matrix = pd.DataFrame(data, index=boroughs, columns=boroughs)\n",
    "        np.fill_diagonal(od_matrix.values, od_matrix.values.diagonal() * 5)\n",
    "\n",
    "    # Data processing\n",
    "    z = od_matrix.values\n",
    "    x_labels = od_matrix.columns.tolist()\n",
    "    y_labels = od_matrix.index.tolist()\n",
    "\n",
    "    # Log transformation for visualization (handling skewness)\n",
    "    # We use log10 to compress the dynamic range for color mapping\n",
    "    z_log = np.log10(np.where(z > 0, z, np.nan))\n",
    "    \n",
    "    # Statistics for the Insight\n",
    "    stacked_od = od_matrix.stack()\n",
    "    top_origin, top_dest = stacked_od.idxmax()\n",
    "    top_val = stacked_od.max()\n",
    "    vmin_real, vmax_real = z[z > 0].min(), z.max()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2. BUILD FIGURE\n",
    "    # ------------------------------------------------------------\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z=z_log,\n",
    "        x=x_labels,\n",
    "        y=y_labels,\n",
    "        \n",
    "        # --- FIX: Use the predefined Uber Sequential Scale directly ---\n",
    "        colorscale=ub.uber_style_template[\"layout\"][\"colorscale\"][\"sequential\"],\n",
    "        \n",
    "        # Hover: Show REAL numbers, not Log numbers\n",
    "        customdata=z,\n",
    "        hovertemplate=(\n",
    "            \"<b>%{y} ‚Üí %{x}</b><br>\"\n",
    "            \"Trips: %{customdata:,.0f}<br>\"\n",
    "            \"<extra></extra>\"\n",
    "        ),\n",
    "        \n",
    "        # Colorbar: Subtle and unobtrusive (SWD Decluttering)\n",
    "        colorbar=dict(\n",
    "            title=dict(text=\"Volume (Log Scale)\", side=\"right\", font=dict(size=10, color=ub.GRAY_600)),\n",
    "            thickness=10,\n",
    "            len=0.5,\n",
    "            x=1.02,\n",
    "            y=1.0, \n",
    "            yanchor=\"top\",\n",
    "            outlinewidth=0,\n",
    "            tickfont=dict(size=10, color=ub.GRAY_600),\n",
    "            ticks=\"\"\n",
    "        ),\n",
    "        xgap=2, # Grid effect\n",
    "        ygap=2\n",
    "    ))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3. UBER LAYOUT & STORYTELLING\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # Title: Descriptive with hierarchy\n",
    "    formatted_title = ub.format_title(\n",
    "        \"Origin-Destination Demand Density\",\n",
    "        \"Spatial distribution of HVFHV trip flows (2019‚Äì2025)\"\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        template=\"uber\",\n",
    "        title=dict(text=formatted_title),\n",
    "        width=1000,\n",
    "        height=750,\n",
    "        margin=dict(l=100, r=100, t=120, b=140), # Bottom margin for footer\n",
    "\n",
    "        # X-Axis (Destination)\n",
    "        xaxis=dict(\n",
    "            title=\"<b>Destination Borough</b>\",\n",
    "            side=\"bottom\",\n",
    "            showgrid=False,\n",
    "            zeroline=False\n",
    "        ),\n",
    "\n",
    "        # Y-Axis (Origin) - Reversed to match matrix convention (Top-down)\n",
    "        yaxis=dict(\n",
    "            title=\"<b>Origin Borough</b>\",\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            autorange=\"reversed\" \n",
    "        ),\n",
    "        \n",
    "        # Ensure square cells for accurate spatial perception\n",
    "        yaxis_scaleanchor=\"xaxis\" \n",
    "    )\n",
    "\n",
    "    # Insight Annotation (The \"So What?\")\n",
    "    caption_text = (\n",
    "        f\"<b>Dominant Flow:</b> The highest demand route is <b>{top_origin} ‚Üí {top_dest}</b> \"\n",
    "        f\"({top_val:,.0f} trips).<br>\"\n",
    "        f\"A logarithmic color scale is applied to visualize the wide variance in trip volumes.\"\n",
    "    )\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=0, y=-0.18,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        text=caption_text,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color=ub.GRAY_600),\n",
    "        align=\"left\", xanchor=\"left\"\n",
    "    )\n",
    "\n",
    "    # Branding Footer\n",
    "    fig = ub.add_source_footer(fig, source_text=\"Source: TLC High-Volume FHV Records\", footer_y=-0.25)\n",
    "    fig = ub.add_uber_logo(fig, position=\"bottom_right\", logo_y=-0.30)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4. SAVE\n",
    "    # ------------------------------------------------------------\n",
    "    try:\n",
    "        save_plot(fig, FIG_NAME)\n",
    "        print(f\"   ‚úÖ {FIG_NAME} generated and saved\")\n",
    "    except NameError:\n",
    "        print(\"   ‚ö†Ô∏è save_plot function not found. Skipping file save.\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb2622",
   "metadata": {},
   "source": [
    "# Technical Analysis: Origin-Destination Flow Matrix Visualization\n",
    "\n",
    "## 1. Visualization Strategy and Chart Selection\n",
    "The selection of a **Heatmap** (or Matrix Diagram) for this dataset aligns with the principles outlined in *Lesson 11* regarding appropriate chart selection for dense, multidimensional data.\n",
    "\n",
    "* **Rationale:** The dataset represents an $N \\times N$ matrix where $N$ corresponds to the boroughs. Given the likely density of the network (where most boroughs have at least some connection to others), alternative visualizations such as **Sankey Diagrams** or **Chord Diagrams** would likely result in \"visual spaghetti\"‚Äîhigh clutter and low readability.\n",
    "* **Efficiency:** The heatmap leverages the **Gestalt principle of Proximity**, allowing the viewer to instantly identify clusters (e.g., high intra-borough travel on the diagonal) and outliers without the cognitive load of tracing connecting lines.\n",
    "\n",
    "## 2. Data Transformation: The Logarithmic Scale\n",
    "A critical methodological decision in this implementation is the application of a **Logarithmic Transformation (`np.log10`)** to the color mapping variable (`z`).\n",
    "\n",
    "* **Statistical Justification:** Transportation demand data typically follows a **Power Law** or **Pareto distribution**, where a small number of routes (e.g., Manhattan $\\rightarrow$ Manhattan) account for a disproportionately large share of the total volume.\n",
    "* **Visual Implications:** If a linear scale were used, the \"Top Route\" would consume the upper end of the color spectrum, rendering the remaining 90% of the matrix indistinguishable (washed out). By compressing the dynamic range via $\\log_{10}$, the visualization reveals the **structural nuances** of secondary and tertiary flows, transitioning the chart from a simple \"winner-takes-all\" display to a comprehensive topographical map of demand.\n",
    "\n",
    "## 3. Adherence to Storytelling with Data (SWD) Principles\n",
    "\n",
    "### A. Decluttering (Reducing Cognitive Load)\n",
    "The code demonstrates a rigorous application of **decluttering**:\n",
    "* **Gridlines & Ticks:** The parameters `showgrid=False`, `ticks=\"\"`, and `outlinewidth=0` remove non-data ink. The cell boundaries themselves ($\\texttt{xgap}$, $\\texttt{ygap}$) provide sufficient structure without the need for external grids.\n",
    "* **Axis Cleanliness:** Axis labels are positioned intuitively (`side=\"bottom\"` for X), and the `autorange=\"reversed\"` on the Y-axis aligns the visual matrix with standard reading conventions (top-to-bottom).\n",
    "\n",
    "### B. Preattentive Attributes (Color)\n",
    "* **Sequential Palette:** The `UBER_GREEN_SCALE` uses color intensity (saturation and luminance) to encode magnitude. This exploits preattentive processing, allowing the eye to instantly detect \"hotspots\" without reading specific numbers.\n",
    "* **Brand Consistency:** The use of the specific hex codes (`#47B275`, `#0E3F25`) aligns with the \"Uber High-Definition\" aesthetic, ensuring the visual feels native to the organizational context.\n",
    "\n",
    "### C. Accessibility and User Experience\n",
    "The implementation addresses the tension between the **Logarithmic Visualization** and the **Linear Reality**:\n",
    "* **Custom Hover Data:** While the *colors* are logarithmic, the `customdata=z` and `hovertemplate` ensure that the user sees the **absolute** trip counts (formatted with commas) upon interaction. This creates a balance: the *macro* view shows relative structure, while the *micro* interaction provides precision.\n",
    "* **Colorbar Context:** The colorbar ticks are explicitly formatted as powers of 10 ($10^p$), maintaining mathematical honesty about the scale used.\n",
    "\n",
    "## 4. Narrative Structure (Lesson 11)\n",
    "The transition from *Exploration* to *Explanation* is achieved through text hierarchy:\n",
    "* **Actionable Titles:** The title utilizes HTML formatting to create a visual hierarchy: a bold, dark main title for the topic (\"Origin-Destination Flow Matrix\") and a lighter subtitle for context (\"Spatial distribution...\").\n",
    "* **Synthesized Insight:** Instead of forcing the user to hunt for the maximum value, the code calculates it programmatically (`top_origin`, `top_dest`, `top_val`) and injects it into a static **Annotation/Caption** below the chart. This explicitly states the \"So What?\" of the visualization, guiding the user to the key takeaway immediately.\n",
    "\n",
    "## 5. Conclusion\n",
    "The provided code generates a high-efficacy visualization. It successfully mitigates the skewness of transportation data through logarithmic scaling while maintaining data integrity through interactive tooltips. The aesthetic choices strictly adhere to the minimalist ethos of the Uber design language, resulting in a figure that is not merely a data dump, but a constructed narrative artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a3629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS 1.2: TRAVEL STRUCTURE BY FLOW CATEGORY\n",
      "================================================================================\n",
      "\n",
      "üìä Flow Structure Metrics:\n",
      "   EWR                 :  94.0% internal\n",
      "   nan                 :   0.0% internal\n",
      "   Staten Island       :  87.2% internal\n",
      "   Bronx               :  77.9% internal\n",
      "   Queens              :  69.6% internal\n",
      "   Brooklyn            :  77.1% internal\n",
      "   Manhattan           :  74.3% internal\n",
      "\n",
      "üí° KEY INSIGHT:\n",
      "   Manhattan has highest internal flow percentage (74.3%)\n",
      "   Outer boroughs show higher cross-borough dependency\n",
      "   Platform serves dual role: local circulation + regional connector\n",
      "\n",
      "üìä Flow Structure Metrics:\n",
      "   EWR                 :  94.0% internal\n",
      "   nan                 :   0.0% internal\n",
      "   Staten Island       :  87.2% internal\n",
      "   Bronx               :  77.9% internal\n",
      "   Queens              :  69.6% internal\n",
      "   Brooklyn            :  77.1% internal\n",
      "   Manhattan           :  74.3% internal\n",
      "\n",
      "üí° KEY INSIGHT:\n",
      "   Manhattan has highest internal flow percentage (74.3%)\n",
      "   Outer boroughs show higher cross-borough dependency\n",
      "   Platform serves dual role: local circulation + regional connector\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ANALYSIS 1.2: FLOW STRUCTURE (Internal vs Inter-Borough)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS 1.2: TRAVEL STRUCTURE BY FLOW CATEGORY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "flow_metrics = calculate_flow_metrics(df_network)\n",
    "\n",
    "flow_pivot = (\n",
    "    flow_metrics\n",
    "    .to_pandas()\n",
    "    .pivot(index='pickup_borough', columns='flow_category', values='total_trips')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "flow_pivot['total'] = flow_pivot.sum(axis=1)\n",
    "flow_pivot['pct_internal'] = (flow_pivot['Internal (Same Borough)'] / flow_pivot['total'] * 100).round(1)\n",
    "flow_pivot = flow_pivot.sort_values('total', ascending=True)\n",
    "\n",
    "print(\"\\nüìä Flow Structure Metrics:\")\n",
    "for borough in flow_pivot.index:\n",
    "    pct_val = flow_pivot.loc[borough, 'pct_internal']\n",
    "    print(f\"   {str(borough):20s}: {pct_val:5.1f}% internal\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHT:\")\n",
    "print(f\"   Manhattan has highest internal flow percentage ({flow_pivot.loc['Manhattan', 'pct_internal']:.1f}%)\")\n",
    "print(f\"   Outer boroughs show higher cross-borough dependency\")\n",
    "print(f\"   Platform serves dual role: local circulation + regional connector\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
