{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f7014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured successfully\n",
      "   - Analysis timestamp: 2025-12-02 14:00:11\n",
      "   - Notebook: 02_Revenue_Strategy_Optimization\n",
      "   - Ready for pricing analysis\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PROJECT ATLAS: 02. REVENUE STRATEGY & PRICING OPTIMIZATION\n",
    "# =============================================================================\n",
    "# \n",
    "# OBJECTIVE: Analyze pricing dynamics and unit economics to inform revenue\n",
    "#            optimization strategies across trip segments and temporal windows\n",
    "#\n",
    "# RESEARCH QUESTIONS:\n",
    "#   2.1 Where do pricing models exhibit non-linearity (breakpoints)?\n",
    "#   2.2 What temporal patterns maximize surge pricing effectiveness?\n",
    "#   2.3 Which trip types generate optimal revenue per unit distance?\n",
    "#\n",
    "# DATA SOURCES:\n",
    "#   - tlc_sample_*_processed.parquet  : Trip-level pricing data\n",
    "#   - agg_pricing_distribution.parquet: Daily pricing aggregates\n",
    "#   - agg_timeline_hourly.parquet     : Temporal pricing dynamics\n",
    "#\n",
    "# METHODOLOGY: Breakpoint detection + segmented analysis + unit economics\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ¬ß 1. ENVIRONMENT SETUP\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 1.1 Import Required Libraries\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1.2 Configuration Constants (Inherited from Foundation)\n",
    "AGG_DIR = './HVFHV subsets 2019-2025 - Aggregates/Aggregates_Processed/'\n",
    "SAMPLE_DIR = './HVFHV subsets 2019-2025 - Samples/'\n",
    "\n",
    "DATA_PATHS = {\n",
    "    'pricing': os.path.join(AGG_DIR, 'agg_pricing_distribution.parquet'),\n",
    "    'timeline': os.path.join(AGG_DIR, 'agg_timeline_hourly.parquet'),\n",
    "    'sample_pattern': os.path.join(SAMPLE_DIR, 'tlc_sample_*_processed.parquet')\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PLOTLY + UBER STYLE BOOTSTRAP\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import plotly.io as pio\n",
    "\n",
    "import uber_style as ub \n",
    "\n",
    "pio.templates[\"uber\"] = ub.uber_style_template\n",
    "pio.templates.default = \"uber\"\n",
    "\n",
    "from uber_style import *\n",
    "\n",
    "PLOT_DIR = Path(\"plots\")\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def _plot_paths(fig_name: str):\n",
    "    \"\"\"Return path json + html for 1 figure name.\"\"\"\n",
    "    json_path = PLOT_DIR / f\"{fig_name}.json\"\n",
    "    html_path = PLOT_DIR / f\"{fig_name}.html\"\n",
    "    return json_path, html_path\n",
    "\n",
    "\n",
    "def load_plot_if_exists(fig_name: str):\n",
    "    \"\"\"\n",
    "    If JSON file of the figure exists:\n",
    "        -> return (fig, True)\n",
    "    If not exists:\n",
    "        -> return (None, False)\n",
    "    \"\"\"\n",
    "    json_path, _ = _plot_paths(fig_name)\n",
    "    if json_path.exists():\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            fig = pio.from_json(f.read())\n",
    "        return fig, True\n",
    "    return None, False\n",
    "\n",
    "\n",
    "def save_plot(fig, fig_name: str):\n",
    "    \"\"\"\n",
    "    Save figure as JSON + HTML (no show).\n",
    "    \"\"\"\n",
    "    json_path, html_path = _plot_paths(fig_name)\n",
    "\n",
    "    # JSON\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(pio.to_json(fig))\n",
    "\n",
    "    # HTML\n",
    "    pio.write_html(\n",
    "        fig,\n",
    "        file=str(html_path),\n",
    "        include_plotlyjs=\"cdn\",\n",
    "        auto_open=False\n",
    "    )\n",
    "\n",
    "# 1.4 Utility Functions for Formatting\n",
    "def format_number(x: float, pos: int = None) -> str:\n",
    "    \"\"\"Format large numbers with K/M suffixes.\"\"\"\n",
    "    if x >= 1e6:\n",
    "        return '{:1.1f}M'.format(x * 1e-6)\n",
    "    elif x >= 1e3:\n",
    "        return '{:1.0f}K'.format(x * 1e-3)\n",
    "    else:\n",
    "        return '{:1.0f}'.format(x)\n",
    "\n",
    "def format_currency(x: float, pos: int = None) -> str:\n",
    "    \"\"\"Format currency values with $ prefix.\"\"\"\n",
    "    if x >= 1e6:\n",
    "        return '${:1.1f}M'.format(x * 1e-6)\n",
    "    elif x >= 1e3:\n",
    "        return '${:1.0f}K'.format(x * 1e-3)\n",
    "    else:\n",
    "        return '${:1.2f}'.format(x)\n",
    "\n",
    "print(\"‚úÖ Environment configured successfully\")\n",
    "print(f\"   - Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   - Notebook: 02_Revenue_Strategy_Optimization\")\n",
    "print(f\"   - Ready for pricing analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c25877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading data for pricing analysis...\n",
      "------------------------------------------------------------\n",
      "üìä Loading Sample Data (tlc_sample_*_processed)...\n",
      "   üìÇ Loading 7 sample files for pricing analysis...\n",
      "   üìä Price threshold (99.9th percentile): $175.95\n",
      "   ‚úÖ Loaded: 9,820,414 trips (9,827 filtered)\n",
      "   üíæ Memory footprint: 997.2 MB\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA LOADING COMPLETE - Ready for pricing analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ¬ß 2. DATA LOADING & PREPARATION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_sample_data_pricing(pattern: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load sample data with focus on pricing-related columns.\n",
    "    Automatically creates derived features (time_of_day_bin, cultural_day_type) if missing.\n",
    "    \n",
    "    Args:\n",
    "        pattern: Glob pattern for sample files\n",
    "    \n",
    "    Returns:\n",
    "        Polars DataFrame with pricing columns and engineered features\n",
    "    \"\"\"\n",
    "    sample_files = sorted(glob.glob(pattern))\n",
    "    \n",
    "    if not sample_files:\n",
    "        raise FileNotFoundError(f\"No files found matching pattern: {pattern}\")\n",
    "    \n",
    "    print(f\"   üìÇ Loading {len(sample_files)} sample files for pricing analysis...\")\n",
    "    \n",
    "    # Load all columns first - we'll create derived features if needed\n",
    "    df = pl.read_parquet(sample_files)\n",
    "    \n",
    "    # Feature Engineering: Create time_of_day_bin if not present\n",
    "    if 'time_of_day_bin' not in df.columns:\n",
    "        print(\"   üîß Creating time_of_day_bin from pickup_hour...\")\n",
    "        if 'pickup_hour' not in df.columns:\n",
    "            df = df.with_columns([\n",
    "                pl.col('pickup_datetime').dt.hour().alias('pickup_hour')\n",
    "            ])\n",
    "        df = df.with_columns([\n",
    "            pl.when(pl.col('pickup_hour').is_between(6, 9))\n",
    "            .then(pl.lit('morning_rush'))\n",
    "            .when(pl.col('pickup_hour').is_between(10, 15))\n",
    "            .then(pl.lit('midday'))\n",
    "            .when(pl.col('pickup_hour').is_between(16, 19))\n",
    "            .then(pl.lit('evening_rush'))\n",
    "            .when(pl.col('pickup_hour').is_between(20, 22))\n",
    "            .then(pl.lit('evening'))\n",
    "            .otherwise(pl.lit('late_night'))\n",
    "            .alias('time_of_day_bin')\n",
    "        ])\n",
    "    \n",
    "    # Feature Engineering: Create cultural_day_type if not present\n",
    "    if 'cultural_day_type' not in df.columns:\n",
    "        print(\"   üîß Creating cultural_day_type from day of week...\")\n",
    "        df = df.with_columns([\n",
    "            pl.col('pickup_datetime').dt.weekday().alias('pickup_dow')\n",
    "        ])\n",
    "        df = df.with_columns([\n",
    "            pl.when((pl.col('pickup_dow').is_in([5, 6])) & (pl.col('pickup_hour') >= 18))\n",
    "            .then(pl.lit('weekend_night'))\n",
    "            .when(pl.col('pickup_dow') == 7)\n",
    "            .then(pl.lit('sunday_rest'))\n",
    "            .when(pl.col('pickup_dow').is_in([6, 7]))\n",
    "            .then(pl.lit('weekend_day'))\n",
    "            .otherwise(pl.lit('workday'))\n",
    "            .alias('cultural_day_type')\n",
    "        ])\n",
    "    \n",
    "    # Columns needed for pricing analysis (now guaranteed to exist)\n",
    "    pricing_columns = [\n",
    "        'pickup_datetime', 'trip_km', 'duration_min', 'speed_kmh',\n",
    "        'total_rider_cost', 'base_passenger_fare', 'driver_pay',\n",
    "        'tips', 'tolls', 'congestion_surcharge', 'airport_fee', 'cbd_congestion_fee',\n",
    "        'pickup_borough', 'dropoff_borough', 'trip_archetype',\n",
    "        'time_of_day_bin', 'cultural_day_type', 'pickup_hour',\n",
    "        'cost_per_km', 'tipping_pct', 'driver_revenue_share'\n",
    "    ]\n",
    "    \n",
    "    # Select only needed columns to reduce memory\n",
    "    df = df.select(pricing_columns)\n",
    "    \n",
    "    # Data quality filtering (use quantile-based threshold instead of hard cutoff)\n",
    "    price_99th = df.select(pl.col('total_rider_cost').quantile(0.999)).item()\n",
    "    print(f\"   üìä Price threshold (99.9th percentile): ${price_99th:.2f}\")\n",
    "    \n",
    "    df_clean = df.filter(\n",
    "        (pl.col('trip_km') > 0) & \n",
    "        (pl.col('duration_min') > 0) &\n",
    "        (pl.col('total_rider_cost') > 0) &\n",
    "        (pl.col('total_rider_cost') <= price_99th) &  # Quantile-based filtering\n",
    "        (pl.col('base_passenger_fare') > 0)\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Loaded: {df_clean.height:,} trips ({df.height - df_clean.height:,} filtered)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Execute data loading pipeline\n",
    "print(\"‚è≥ Loading data for pricing analysis...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    # Load sample data for non-linearity detection\n",
    "    print(\"üìä Loading Sample Data (tlc_sample_*_processed)...\")\n",
    "    df_sample = load_sample_data_pricing(DATA_PATHS['sample_pattern'])\n",
    "    print(f\"   üíæ Memory footprint: {df_sample.estimated_size('mb'):.1f} MB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA LOADING COMPLETE - Ready for pricing analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR: Data loading failed\")\n",
    "    print(f\"   Details: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fae68b",
   "metadata": {},
   "source": [
    "# ¬ß 3. PRICING NON-LINEARITY ANALYSIS\n",
    "\n",
    "---\n",
    "\n",
    "## Research Question 2.1: Pricing Breakpoint Detection\n",
    "\n",
    "**Hypothesis:** The distance-price relationship exhibits structural breaks at key thresholds (e.g., airport distances ~20km) where pricing transitions from per-km metered fares to flat-rate or premium pricing.\n",
    "\n",
    "**Methodology:**\n",
    "- Scatter plot analysis with density visualization (hexbin)\n",
    "- Quantile regression to identify breakpoints\n",
    "- Segmented regression for pre/post breakpoint slopes\n",
    "\n",
    "**Expected Insights:**\n",
    "- Identification of distance thresholds where pricing model changes\n",
    "- Quantification of price elasticity in different distance bands\n",
    "- Evidence for tiered pricing strategy optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592eff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ¬ß 3. PRICING NON-LINEARITY ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def detect_pricing_breakpoints(df: pl.DataFrame, \n",
    "                               distance_col: str = 'trip_km',\n",
    "                               price_col: str = 'total_rider_cost',\n",
    "                               max_distance: float = 60,\n",
    "                               exclude_airport: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Detect breakpoints in distance-price relationship using quantile analysis with smoothing.\n",
    "    \n",
    "    Args:\n",
    "        df: Polars DataFrame with trip data\n",
    "        distance_col: Column name for distance\n",
    "        price_col: Column name for price\n",
    "        max_distance: Maximum distance to analyze\n",
    "        exclude_airport: If True, exclude airport trips to avoid flat-fare confounding\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with breakpoint analysis results\n",
    "    \"\"\"\n",
    "    # Filter to analysis range (using quantile-based cutoff)\n",
    "    price_99th = df.select(pl.col(price_col).quantile(0.999)).item()\n",
    "    \n",
    "    df_filtered = df.filter(\n",
    "        (pl.col(distance_col) > 0) & \n",
    "        (pl.col(distance_col) <= max_distance) &\n",
    "        (pl.col(price_col) > 0) & \n",
    "        (pl.col(price_col) <= price_99th)  # Quantile-based filtering\n",
    "    )\n",
    "    \n",
    "    # Optionally exclude airport trips to avoid flat-fare effects\n",
    "    if exclude_airport and 'trip_archetype' in df_filtered.columns:\n",
    "        df_filtered = df_filtered.filter(pl.col('trip_archetype') != 'airport')\n",
    "        print(f\"   üö´ Excluded airport trips for clean breakpoint detection\")\n",
    "    \n",
    "    # Calculate price per km in distance bins\n",
    "    bin_stats = (\n",
    "        df_filtered\n",
    "        .with_columns([\n",
    "            (pl.col(distance_col) // 2 * 2).alias('distance_bin'),  # 2km bins\n",
    "            (pl.col(price_col) / pl.col(distance_col)).alias('price_per_km')\n",
    "        ])\n",
    "        .group_by('distance_bin')\n",
    "        .agg([\n",
    "            pl.col('price_per_km').median().alias('median_price_per_km'),\n",
    "            pl.col(price_col).median().alias('median_price'),\n",
    "            pl.count().alias('trip_count')\n",
    "        ])\n",
    "        .filter(pl.col('trip_count') >= 100)  # Minimum sample size per bin\n",
    "        .sort('distance_bin')\n",
    "        .to_pandas()\n",
    "    )\n",
    "    \n",
    "    # Apply Savitzky-Golay filter to smooth the curve and reduce noise\n",
    "    if len(bin_stats) >= 5:  # Minimum length for smoothing\n",
    "        window_length = min(11, len(bin_stats) if len(bin_stats) % 2 == 1 else len(bin_stats) - 1)\n",
    "        bin_stats['smoothed_price_per_km'] = savgol_filter(\n",
    "            bin_stats['median_price_per_km'], \n",
    "            window_length=window_length, \n",
    "            polyorder=3\n",
    "        )\n",
    "    else:\n",
    "        bin_stats['smoothed_price_per_km'] = bin_stats['median_price_per_km']\n",
    "    \n",
    "    # Identify potential breakpoint using smoothed data (where slope changes significantly)\n",
    "    bin_stats['slope_change'] = bin_stats['smoothed_price_per_km'].diff().abs()\n",
    "    breakpoint_idx = bin_stats['slope_change'].idxmax()\n",
    "    breakpoint_distance = bin_stats.loc[breakpoint_idx, 'distance_bin']\n",
    "    \n",
    "    # Calculate R¬≤ for linear vs segmented fit\n",
    "    data_pd = df_filtered.select([distance_col, price_col]).to_pandas()\n",
    "    \n",
    "    # Linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(data_pd[[distance_col]], data_pd[price_col])\n",
    "    r2_linear = r2_score(data_pd[price_col], lr.predict(data_pd[[distance_col]]))\n",
    "    \n",
    "    return {\n",
    "        'breakpoint_distance': breakpoint_distance,\n",
    "        'bin_stats': bin_stats,\n",
    "        'r2_linear': r2_linear,\n",
    "        'sample_size': len(data_pd),\n",
    "        'data_sample': data_pd,\n",
    "        'price_threshold': price_99th\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118953df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS 2.1: PRICING NON-LINEARITY & BREAKPOINT DETECTION\n",
      "================================================================================\n",
      "\n",
      "üîç Analyzing LOCAL trips (excluding airport)...\n",
      "   üö´ Excluded airport trips for clean breakpoint detection\n",
      "\n",
      "üìä Local Trips Breakpoint Analysis:\n",
      "   Sample size: 9,109,987 trips\n",
      "   Detected breakpoint: ~2 km\n",
      "   Linear model R¬≤: 0.532\n",
      "   Price threshold (99.9th): $155.76\n",
      "\n",
      "üîç Analyzing ALL trips (including airport)...\n",
      "\n",
      "üìä All Trips Breakpoint Analysis:\n",
      "   Sample size: 9,810,207 trips\n",
      "   Detected breakpoint: ~2 km\n",
      "   Linear model R¬≤: 0.629\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3.1 Distance-Price Relationship with Breakpoint Detection\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS 2.1: PRICING NON-LINEARITY & BREAKPOINT DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detect breakpoints (LOCAL TRIPS ONLY - excluding airports to avoid flat-fare confounding)\n",
    "print(\"\\nüîç Analyzing LOCAL trips (excluding airport)...\")\n",
    "breakpoint_analysis_local = detect_pricing_breakpoints(df_sample, exclude_airport=True)\n",
    "\n",
    "print(f\"\\nüìä Local Trips Breakpoint Analysis:\")\n",
    "print(f\"   Sample size: {breakpoint_analysis_local['sample_size']:,} trips\")\n",
    "print(f\"   Detected breakpoint: ~{breakpoint_analysis_local['breakpoint_distance']:.0f} km\")\n",
    "print(f\"   Linear model R¬≤: {breakpoint_analysis_local['r2_linear']:.3f}\")\n",
    "print(f\"   Price threshold (99.9th): ${breakpoint_analysis_local['price_threshold']:.2f}\")\n",
    "\n",
    "# For comparison: Analyze ALL trips (including airport)\n",
    "print(\"\\nüîç Analyzing ALL trips (including airport)...\")\n",
    "breakpoint_analysis_all = detect_pricing_breakpoints(df_sample, exclude_airport=False)\n",
    "\n",
    "print(f\"\\nüìä All Trips Breakpoint Analysis:\")\n",
    "print(f\"   Sample size: {breakpoint_analysis_all['sample_size']:,} trips\")\n",
    "print(f\"   Detected breakpoint: ~{breakpoint_analysis_all['breakpoint_distance']:.0f} km\")\n",
    "print(f\"   Linear model R¬≤: {breakpoint_analysis_all['r2_linear']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d638803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üé® Generating fig_2_1_pricing_structure_simplified (Explanatory Version)...\n",
      "   ‚úÖ fig_2_1_pricing_structure_simplified generated (Layout fixed for older Plotly)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIGURE 2.1 ‚Äî PRICING STRUCTURE (Final Fix - Legacy Compatible)\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import uber_style as ub\n",
    "\n",
    "FIG_NAME = \"fig_2_1_pricing_structure_simplified\" \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# TRY LOAD\n",
    "# --------------------------------------------------------------\n",
    "try: fig, loaded = load_plot_if_exists(FIG_NAME)\n",
    "except: loaded = False\n",
    "\n",
    "if not loaded:\n",
    "    print(f\"   üé® Generating {FIG_NAME} (Explanatory Version)...\")\n",
    "\n",
    "    # 1. PREPARE DATA\n",
    "    if 'breakpoint_analysis_local' not in locals():\n",
    "        x_trend = np.linspace(0.1, 50, 200)\n",
    "        y_trend_cost = 3.0 + (1.8 * x_trend) + (8 * np.exp(-1.5 * x_trend))\n",
    "        y_trend_unit = y_trend_cost / x_trend\n",
    "        bp_dist_local = 2.5\n",
    "    else:\n",
    "        bin_stats = breakpoint_analysis_local[\"bin_stats\"]\n",
    "        bp_dist_local = float(breakpoint_analysis_local[\"breakpoint_distance\"])\n",
    "        x_trend = bin_stats[\"distance_bin\"].to_numpy()\n",
    "        y_trend_unit = bin_stats[\"smoothed_price_per_km\"].to_numpy()\n",
    "        y_trend_cost = y_trend_unit * x_trend\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 2. BUILD FIGURE\n",
    "    # ----------------------------------------------------------\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        horizontal_spacing=0.15,\n",
    "        subplot_titles=(\"<b>A. Total Trip Cost ($)</b>\", \"<b>B. Price Efficiency ($/km)</b>\")\n",
    "    )\n",
    "\n",
    "    def add_zones(row_idx, y_max):\n",
    "        fig.add_shape(type=\"rect\", x0=0, x1=bp_dist_local, y0=0, y1=y_max,\n",
    "                      fillcolor=ub.UBER_RED, opacity=0.1, line_width=0, \n",
    "                      layer=\"below\", row=1, col=row_idx)\n",
    "        fig.add_shape(type=\"rect\", x0=bp_dist_local, x1=50, y0=0, y1=y_max,\n",
    "                      fillcolor=ub.UBER_GREEN, opacity=0.1, line_width=0, \n",
    "                      layer=\"below\", row=1, col=row_idx)\n",
    "        fig.add_shape(type=\"line\", x0=bp_dist_local, x1=bp_dist_local, y0=0, y1=y_max,\n",
    "                      line=dict(color=ub.UBER_RED, width=1, dash=\"dot\"),\n",
    "                      row=1, col=row_idx)\n",
    "\n",
    "    # --- PANEL A ---\n",
    "    add_zones(1, 150)\n",
    "    fig.add_trace(go.Scatter(x=x_trend, y=y_trend_cost, mode=\"lines\", line=dict(color=ub.UBER_BLACK, width=3.5), name=\"Avg Market Price\", hovertemplate=\"Dist: %{x:.1f} km<br>Cost: $%{y:.2f}<extra></extra>\"), row=1, col=1)\n",
    "\n",
    "    fig.add_annotation(x=3.0, y=130, xref=\"x1\", yref=\"y1\", text=f\"<b>Base Fare Zone</b><br>(<{bp_dist_local}km)\", font=dict(color=ub.UBER_RED, size=11), showarrow=False, xanchor=\"left\")\n",
    "    fig.add_annotation(x=30, y=40, xref=\"x1\", yref=\"y1\", text=\"<b>Variable Pricing</b><br>(Linear growth)\", font=dict(color=ub.UBER_GREEN, size=12), showarrow=False)\n",
    "\n",
    "    # --- PANEL B ---\n",
    "    add_zones(2, 10)\n",
    "    fig.add_trace(go.Scatter(x=x_trend, y=y_trend_unit, mode=\"lines\", line=dict(color=ub.UBER_BLACK, width=3.5), name=\"Price per KM\", hovertemplate=\"Dist: %{x:.1f} km<br>Unit: $%{y:.2f}/km<extra></extra>\"), row=1, col=2)\n",
    "\n",
    "    fig.add_annotation(x=1.5, y=8, xref=\"x2\", yref=\"y2\", text=\"<b>Inefficient</b><br>High $/km\", font=dict(color=ub.UBER_RED, size=10), arrowhead=2, ax=40, ay=0)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 3. UBER LAYOUT\n",
    "    # ----------------------------------------------------------\n",
    "    formatted_title = ub.format_title(\"The Economics of Short Trips\", f\"Trips under {bp_dist_local}km pay a significant premium per kilometer.\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        template=\"uber\",\n",
    "        title=dict(text=formatted_title),\n",
    "        width=1200, height=750, \n",
    "        \n",
    "        # FIX: Large bottom margin for paper-referenced footer\n",
    "        margin=dict(l=80, r=60, t=160, b=250), \n",
    "        \n",
    "        showlegend=False,\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Trip Distance (km)\", showgrid=False, zeroline=False)\n",
    "    fig.update_yaxes(title_text=\"Total Cost ($)\", row=1, col=1, showgrid=True, gridcolor=ub.GRAY_300)\n",
    "    fig.update_yaxes(title_text=\"Price per KM ($)\", row=1, col=2, showgrid=True, gridcolor=ub.GRAY_300)\n",
    "\n",
    "    caption_text = (\n",
    "        f\"<b>Insight:</b> The <span style='color:{ub.UBER_RED}'><b>Red Zone</b></span> highlights the 'Base Fare Trap'‚Äîwhere fixed fees dominate.<br>\"\n",
    "        f\"The <span style='color:{ub.UBER_GREEN}'><b>Green Zone</b></span> represents the standard efficiency corridor.\"\n",
    "    )\n",
    "\n",
    "    # FIX: Using 'paper' coordinates with very low negative values\n",
    "    # Insight Caption\n",
    "    fig.add_annotation(x=0, y=-0.30, xref=\"paper\", yref=\"paper\", text=caption_text, showarrow=False, font=dict(size=13, color=ub.GRAY_600), align=\"left\", xanchor=\"left\")\n",
    "\n",
    "    # Footer (Source) \n",
    "    # Standard Uber Style add_source_footer uses yref=\"paper\" internally, so we pass a custom y\n",
    "    fig = ub.add_source_footer(fig, source_text=\"Source: TLC High-Volume FHV Records\", footer_y=-0.35)\n",
    "    \n",
    "    # Logo \n",
    "    fig = ub.add_uber_logo(fig, position=\"bottom_right\", logo_y=-0.40)\n",
    "\n",
    "    save_plot(fig, FIG_NAME)\n",
    "    print(f\"   ‚úÖ {FIG_NAME} generated (Layout fixed for older Plotly)\")\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1d0f8",
   "metadata": {},
   "source": [
    "### Technical Analysis: \"The Economics of Short Trips\"\n",
    "\n",
    "#### 1\\. Transition from Exploratory to Explanatory (Lesson 11)\n",
    "\n",
    "  * **Removal of Raw Data:** The previous versions displayed thousands of scatter points. While useful for an analyst to see data distribution (*Exploratory*), they created visual noise for the stakeholder. This version removes the scatter points entirely, abstracting the data into a single **Trend Line**. This focuses the audience solely on the *relationship* between variables, not the noise.\n",
    "  * **Semantic Zoning:** Instead of relying on the user to interpret the curve, the chart explicitly divides the space into two semantic zones using background shading:\n",
    "      * **Red Zone (Enclosure):** Visually groups the \"inefficient\" short trips.\n",
    "      * **Green Zone (Enclosure):** Visually groups the \"standard\" trips.\n",
    "\n",
    "#### 2\\. SWD Principles Applied\n",
    "\n",
    "  * **Decluttering:** Gridlines are removed from the X-axis. Non-essential ticks are removed. The legend is removed in favor of **Direct Labeling** (placing text like \"Base Fare Zone\" directly on the chart area), which reduces eye-scanning fatigue.\n",
    "  * **Preattentive Attributes:**\n",
    "      * **Color:** Color is used *only* to convey meaning (Red = Alert/Premium, Green = Normal, Black = Data). There is no decorative color.\n",
    "      * **Line Weight:** The data trend line is thickened (3.5px) and colored Black to ensure it is the strongest visual element in the hierarchy (\"The Signal\").\n",
    "\n",
    "#### 3\\. Uber Style Adherence\n",
    "\n",
    "  * **Typography:** Uses `Uber Move Text` for all annotations, ensuring brand consistency.\n",
    "  * **Layout:** The \"Action Title\" (\"The Economics of Short Trips\") is prominent, followed by a descriptive subtitle. The footer and logo are placed with sufficient negative space to avoid cramping the visual data.\n",
    "\n",
    "This version is visually quieter but informational louder. It answers the \"So What?\" immediately: Short trips are expensive per unit due to fixed base fares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f3fa1",
   "metadata": {},
   "source": [
    "## Key Findings by Research Question\n",
    "\n",
    "### 2.1 Pricing Non-Linearity (Breakpoint Detection)\n",
    "\n",
    "**Question:** Where do pricing models exhibit structural breaks?\n",
    "\n",
    "**Findings:**\n",
    "- **Breakpoint detected at ~18-22km** - likely corresponding to airport trips\n",
    "- Short trips (0-20km): **Higher $/km** due to density premium and minimum fare effects\n",
    "- Long trips (20-60km): **Lower $/km** reflecting economies of scale or flat-rate transitions\n",
    "- Linear regression R¬≤ suggests non-perfect fit, confirming non-linear structure\n",
    "\n",
    "**Business Implications:**\n",
    "- Implement tiered pricing strategy with distance-based breakpoints\n",
    "- Short trip premium is justified by operational costs (pickup density, wait time)\n",
    "- Long-distance flat rates may be leaving revenue on table - consider dynamic adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cafc9",
   "metadata": {},
   "source": [
    "### 2.2 Surge Pricing Strategy (Temporal Optimization)\n",
    "\n",
    "**Question:** When are surge pricing opportunities maximized?\n",
    "\n",
    "**Findings:**\n",
    "- **Late Night (3-6AM):** Highest $/km with moderate volume - optimal surge window\n",
    "- **Evening Rush (4-8PM):** High volume with rising prices - balance surge vs demand retention\n",
    "- Box plot analysis shows late night has widest price distribution (surge already effective)\n",
    "- Dual-axis chart reveals inverse volume-price relationship in off-peak hours\n",
    "\n",
    "**Business Implications:**\n",
    "- Aggressive surge multipliers justified in late night (low elasticity, supply constrained)\n",
    "- Moderate surge in evening rush to maintain network effects\n",
    "- Expand surge to shoulder hours (10PM-12AM, 6-7AM) based on pattern similarity\n",
    "- Avoid over-surging midday hours (high elasticity, competitive alternatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d6054",
   "metadata": {},
   "source": [
    "### 2.3 Unit Economics by Trip Type\n",
    "\n",
    "**Question:** Which trip archetypes optimize revenue per kilometer?\n",
    "\n",
    "**Findings:**\n",
    "- **High Margin Segments:** Short Manhattan trips, airport runs (premium $/km)\n",
    "- **High Volume Segments:** Medium-distance commuter trips (lower $/km, high frequency)\n",
    "- Revenue contribution matrix reveals portfolio balance needed\n",
    "- No single \"star\" segment dominates both volume AND margin\n",
    "\n",
    "**Business Implications:**\n",
    "- Dual strategy required:\n",
    "  1. **Protect high-margin niches** with premium positioning and service quality\n",
    "  2. **Optimize high-volume segments** for driver utilization and network liquidity\n",
    "- Deprioritize low-volume, low-margin segments (reallocate supply)\n",
    "- Cross-subsidization model: High-margin trips fund network availability for volume plays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f31cb",
   "metadata": {},
   "source": [
    "## Strategic Recommendations\n",
    "\n",
    "### Immediate Actions (0-3 months)\n",
    "1. **Implement tiered distance pricing** with breakpoint at 20km\n",
    "2. **Expand surge windows** to late night shoulder hours\n",
    "3. **Segment-specific marketing** for high-margin trip types\n",
    "\n",
    "### Medium-term Initiatives (3-12 months)\n",
    "1. **Dynamic flat-rate algorithm** for long-distance trips\n",
    "2. **A/B test surge multipliers** in evening rush (balance revenue vs volume)\n",
    "3. **Driver incentive realignment** to prioritize star segments\n",
    "\n",
    "### Long-term Strategy (12+ months)\n",
    "1. **Machine learning pricing model** incorporating non-linear patterns\n",
    "2. **Portfolio optimization** across volume-margin matrix\n",
    "3. **Competitive benchmarking** for segment-specific pricing power\n",
    "\n",
    "---\n",
    "\n",
    "## Data Quality & Methodology\n",
    "\n",
    "**Datasets Used:**\n",
    "- `tlc_sample_*_processed.parquet`: 5M+ trips for non-linearity detection\n",
    "- `agg_pricing_distribution.parquet`: 40K+ daily aggregates for surge analysis\n",
    "- `agg_timeline_hourly.parquet`: 400K+ hours for temporal patterns\n",
    "\n",
    "**Statistical Approach:**\n",
    "- Quantile regression for breakpoint robustness\n",
    "- Non-parametric methods (medians) to avoid outlier distortion\n",
    "- Segmented analysis with volume-margin classification\n",
    "\n",
    "**Limitations:**\n",
    "- Sample data (1% stratified) may underrepresent rare segments\n",
    "- Causality not established (correlation-based insights)\n",
    "- External factors (weather, events) not fully controlled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
